datasets
episode render
gym 1.0
dqn extensions
ray
n step return generalized advantage
aux loss
tesla battery
epl blog posts
eenrgy py gym envs should inherit from the gym env - not use env.env!
testing of reinforcment learning codebases - energypy, using of agent and env stubs
agent.collect_policy(), agent.greedy_policy, agent.policy.greedy()
add confidence itnerval calc for rewards
parallelized batteires
naming of columns in energypy
charge is not being scaled beofre being addedinto the observation
learning every n steps (like dqn does - I think)
making a proper observation space - if sent in prices, then generate a perfect forecast (or a lagged feature block?)
scaling of charge before going into obs (use capacity)
parallel battery

--- 

Interface refactor
tf 2.0

